"""
WebSocket STT —Å–µ—Ä–≤–µ—Ä - –¢–û–õ–¨–ö–û —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
–û–±—ã—á–Ω—ã–π OpenAI Whisper Small (–Ω–µ faster-whisper)
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –Ω–∞ GPU
"""
import warnings
warnings.filterwarnings("ignore")

# –ê–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
import subprocess
import sys

def install_if_missing(package, import_name=None):
    if import_name is None:
        import_name = package
    try:
        __import__(import_name)
    except ImportError:
        print(f"üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package, "-q"])
        print(f"‚úÖ {package} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã
install_if_missing("openai-whisper", "whisper")
install_if_missing("torch")
install_if_missing("numpy")
install_if_missing("websockets")
print()

import asyncio
import websockets
import json
import whisper
import torch
import numpy as np
from datetime import datetime
import base64
import time

# ============ –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò ============
print("=" * 80)
print("üöÄ WEBSOCKET STT –°–ï–†–í–ï–† (WHISPER SMALL)")
print("=" * 80)

# –§–æ—Ä—Å–∏—Ä—É–µ–º GPU —Ä–µ–∂–∏–º
if not torch.cuda.is_available():
    print("‚ùå CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit –∏ GPU –¥—Ä–∞–π–≤–µ—Ä—ã")
    print("   https://developer.nvidia.com/cuda-downloads")
    import sys
    sys.exit(1)

device = "cuda"
print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—ã—á–Ω—ã–π Whisper Small
print(f"üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper Small ({device.upper()})...")
start_time = time.time()
whisper_model = whisper.load_model("small", device=device)
load_time = time.time() - start_time
print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f}—Å\n")

print("=" * 80)
print(f"üåê WebSocket —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –Ω–∞ ws://0.0.0.0:8765")
print(f"üìä –†–µ–∂–∏–º: {device.upper()}")
print("=" * 80)
print()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
SAMPLE_RATE = 16000


async def handle_client(websocket, path):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞"""
    client_id = f"{websocket.remote_address[0]}:{websocket.remote_address[1]}"
    print(f"üéôÔ∏è  –ü–æ–¥–∫–ª—é—á–∏–ª—Å—è: {client_id}")
    
    audio_buffer = []
    
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
        await websocket.send(json.dumps({
            "type": "connected",
            "message": "STT server ready",
            "device": device,
            "sample_rate": SAMPLE_RATE
        }))
        
        async for message in websocket:
            data = json.loads(message)
            msg_type = data.get("type", "audio")
            
            # ============ –ê–£–î–ò–û ============
            if msg_type == "audio":
                audio_chunk = np.frombuffer(
                    base64.b64decode(data["audio"]),
                    dtype=np.int16
                ).astype(np.float32) / 32768.0
                
                audio_buffer.append(audio_chunk)
            
            # ============ –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø ============
            elif msg_type == "finalize":
                if not audio_buffer:
                    await websocket.send(json.dumps({
                        "type": "transcription",
                        "text": "",
                        "is_final": True,
                        "timestamp": datetime.now().isoformat()
                    }))
                    continue
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞—É–¥–∏–æ
                audio = np.concatenate(audio_buffer)
                audio_buffer = []
                
                duration = len(audio) / SAMPLE_RATE
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º (–æ–±—ã—á–Ω—ã–π Whisper —Å hotwords)
                start_time = time.time()
                result = whisper_model.transcribe(
                    audio,
                    language="en",
                    initial_prompt="Kiko, kiko, KIKO, Kiko assistant, voice assistant Kiko",
                    fp16=True
                )
                
                text = result["text"].strip()
                transcribe_time = time.time() - start_time
                rtf = transcribe_time / duration if duration > 0 else 0
                
                print(f"üß† [{client_id}] {text!r}")
                print(f"‚è±Ô∏è  {duration:.2f}s –∞—É–¥–∏–æ ‚Üí {transcribe_time*1000:.0f}ms –æ–±—Ä–∞–±–æ—Ç–∫–∏ (RTF: {rtf:.3f}x)")
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                response = {
                    "type": "transcription",
                    "text": text,
                    "is_final": True,
                    "language": result.get("language", "ru"),
                    "timestamp": datetime.now().isoformat(),
                    "metrics": {
                        "audio_duration_s": round(duration, 3),
                        "transcription_time_s": round(transcribe_time, 3),
                        "transcription_time_ms": round(transcribe_time * 1000, 2),
                        "realtime_factor": round(rtf, 3),
                        "samples": len(audio)
                    }
                }
                
                await websocket.send(json.dumps(response))
    
    except websockets.exceptions.ConnectionClosed:
        print(f"üëã –û—Ç–∫–ª—é—á–∏–ª—Å—è: {client_id}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ [{client_id}]: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞"""
    host = "0.0.0.0"
    port = 8765
    
    print(f"üéß –û–∂–∏–¥–∞—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π...")
    
    async with websockets.serve(handle_client, host, port, max_size=10_000_000):
        await asyncio.Future()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nüëã –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
