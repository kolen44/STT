"""
WebSocket STT —Å–µ—Ä–≤–µ—Ä - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
OpenAI Whisper Small –Ω–∞ GPU
"""
import warnings
warnings.filterwarnings("ignore")

import asyncio
import websockets
import json
import whisper
import torch
import numpy as np
from datetime import datetime
import base64
import time
from collections import defaultdict
import re
from difflib import get_close_matches

# ============ –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò ============
print("=" * 80)
print("üöÄ WEBSOCKET STT SUPER SERVER (WHISPER SMALL)")
print("=" * 80)

# –§–æ—Ä—Å–∏—Ä—É–µ–º GPU —Ä–µ–∂–∏–º
if not torch.cuda.is_available():
    print("‚ùå CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit –∏ GPU –¥—Ä–∞–π–≤–µ—Ä—ã")
    print("   https://developer.nvidia.com/cuda-downloads")
    import sys
    sys.exit(1)

device = "cuda"
print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper Small
print(f"üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper Small ({device.upper()})...")
start_time = time.time()
whisper_model = whisper.load_model("small", device=device)
load_time = time.time() - start_time
print(f"‚úÖ Whisper –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {load_time:.2f}—Å\n")

print("=" * 80)
print(f"üåê WebSocket —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –Ω–∞ ws://0.0.0.0:8765")
print(f"üìä –†–µ–∂–∏–º: {device.upper()}")
print("=" * 80)
print()

# ===============================
# –ù–ê–°–¢–†–û–ô–ö–ò
# ===============================
SAMPLE_RATE = 16000

# Hotwords –¥–ª—è boosting —Å –≤–µ—Å–∞–º–∏
HOTWORDS = ["Kiko", "kiko", "KIKO", "–∫–∏–∫–æ", "–∫—ñ–∫–æ"]

# Initial prompt –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
INITIAL_PROMPT = "Kiko is a voice assistant. Common words: Kiko, hello, play, stop, volume, turn on, turn off."

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è post-correction (<1ms –Ω–∞–≥—Ä—É–∑–∫–∏)
CORRECTION_DICT = {
    "kiko": "Kiko",
    "kyko": "Kiko",
    "keeko": "Kiko",
    "kico": "Kiko",
    "kieko": "Kiko",
    "keyko": "Kiko",
    "tico": "Kiko",
    "tiko": "Kiko",
}

# –°–ª–æ–≤–∞—Ä—å —Å–ø–∏–∫–µ—Ä–æ–≤ (–ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã)
speakers_sessions = defaultdict(dict)
speaker_counter = defaultdict(int)

# ===============================
# UTILS
# ===============================
def apply_post_correction(text):
    """–ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Å—Ç-–∫–æ—Ä—Ä–µ–∫—Ü–∏—é —Ç–µ–∫—Å—Ç–∞ (<1ms)"""
    if not text:
        return text
    
    words = text.split()
    corrected_words = []
    
    for word in words:
        # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        clean_word = re.sub(r'[^\w\s]', '', word).lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if clean_word in CORRECTION_DICT:
            corrected = word.replace(clean_word, CORRECTION_DICT[clean_word])
            corrected = corrected.replace(clean_word.capitalize(), CORRECTION_DICT[clean_word])
            corrected_words.append(corrected)
        # Fuzzy match –¥–ª—è –æ–ø–µ—á–∞—Ç–æ–∫
        elif len(clean_word) > 2:
            matches = get_close_matches(clean_word, CORRECTION_DICT.keys(), n=1, cutoff=0.8)
            if matches:
                corrected = word.replace(clean_word, CORRECTION_DICT[matches[0]])
                corrected = corrected.replace(clean_word.capitalize(), CORRECTION_DICT[matches[0]])
                corrected_words.append(corrected)
            else:
                corrected_words.append(word)
        else:
            corrected_words.append(word)
    
    return ' '.join(corrected_words)


def simple_noise_gate(audio_data, threshold=0.01):
    """–ü—Ä–æ—Å—Ç–æ–π noise gate - –æ–±–Ω—É–ª—è–µ–º —Ç–∏—Ö–∏–µ —É—á–∞—Å—Ç–∫–∏ (–ø–æ—á—Ç–∏ 0ms)"""
    audio_abs = np.abs(audio_data)
    mask = audio_abs > threshold
    return audio_data * mask


def get_speaker_hash(audio_data):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–ø–∏–∫–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞"""
    # –ë–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    mean_amplitude = np.mean(np.abs(audio_data))
    std_amplitude = np.std(audio_data)
    zero_crossings = np.sum(np.diff(np.sign(audio_data)) != 0)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞–∑–ª–∏—á–∏—è
    # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
    fft = np.fft.rfft(audio_data)
    magnitude = np.abs(fft)
    spectral_centroid = np.sum(magnitude * np.arange(len(magnitude))) / np.sum(magnitude) if np.sum(magnitude) > 0 else 0
    
    # –≠–Ω–µ—Ä–≥–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö
    low_freq_energy = np.sum(magnitude[:len(magnitude)//4])
    high_freq_energy = np.sum(magnitude[3*len(magnitude)//4:])
    
    # –°–æ–∑–¥–∞—ë–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π "–æ—Ç–ø–µ—á–∞—Ç–æ–∫"
    speaker_hash = f"{mean_amplitude:.5f}_{std_amplitude:.5f}_{zero_crossings}_{spectral_centroid:.2f}_{low_freq_energy:.2f}_{high_freq_energy:.2f}"
    return speaker_hash


def get_speaker_number(client_id, speaker_hash):
    """–ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä —Å–ø–∏–∫–µ—Ä–∞ –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π"""
    if speaker_hash not in speakers_sessions[client_id]:
        speaker_counter[client_id] += 1
        speakers_sessions[client_id][speaker_hash] = speaker_counter[client_id]
    return speakers_sessions[client_id][speaker_hash]


# ===============================
# WS HANDLER
# ===============================
async def handle_client(websocket):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞"""
    client_id = id(websocket)
    print(f"üîå –ö–ª–∏–µ–Ω—Ç –ø–æ–¥–∫–ª—é—á–∏–ª—Å—è: {client_id}")

    audio_buffer = []

    try:
        await websocket.send(json.dumps({
            "type": "connected",
            "message": "Real-time transcription server ready",
            "sample_rate": SAMPLE_RATE,
            "model": "small",
            "device": device,
        }))

        async for message in websocket:
            try:
                data = json.loads(message)
                msg_type = data.get("type")

                if msg_type == "audio":
                    audio_b64 = data.get("audio") or ""
                    if not audio_b64:
                        continue
                    
                    audio_chunk = np.frombuffer(
                        base64.b64decode(audio_b64),
                        dtype=np.int16
                    ).astype(np.float32) / 32768.0
                    
                    audio_buffer.append(audio_chunk)

                elif msg_type == "finalize":
                    if not audio_buffer:
                        await websocket.send(json.dumps({
                            "type": "transcription",
                            "text": "",
                            "is_final": True,
                            "timestamp": datetime.now().isoformat(),
                        }))
                        continue

                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞—É–¥–∏–æ
                    audio = np.concatenate(audio_buffer)
                    audio_buffer = []
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç–æ–π noise gate (–ø–æ—á—Ç–∏ 0ms –Ω–∞–≥—Ä—É–∑–∫–∏)
                    audio = simple_noise_gate(audio, threshold=0.01)
                    
                    audio_duration = len(audio) / SAMPLE_RATE
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏–∫–µ—Ä–∞
                    speaker_hash = get_speaker_hash(audio)
                    speaker_num = get_speaker_number(client_id, speaker_hash)
                    
                    print(f"üéß [{client_id}] Speaker #{speaker_num} | samples={len(audio)} duration={audio_duration:.3f}s")

                    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å hotwords –∏ initial_prompt
                    start_time = time.perf_counter()
                    
                    result = whisper_model.transcribe(
                        audio,
                        language="en",
                        initial_prompt=INITIAL_PROMPT,
                        fp16=True
                    )
                    
                    text = result["text"].strip()
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º post-correction (<1ms)
                    text = apply_post_correction(text)
                    
                    end_time = time.perf_counter()
                    transcription_time = (end_time - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
                    
                    rtf = audio_duration / (transcription_time / 1000) if transcription_time > 0 else 0

                    print(f"üìù [{client_id}] Speaker #{speaker_num}: {text!r}")
                    print(f"‚è±Ô∏è  –í—Ä–µ–º—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {transcription_time:.2f}ms ({transcription_time/1000:.3f}s) | RTF: {rtf:.2f}x")

                    await websocket.send(json.dumps({
                        "type": "transcription",
                        "text": text,
                        "is_final": True,
                        "timestamp": datetime.now().isoformat(),
                        "speaker_number": speaker_num,
                        "metrics": {
                            "transcription_time_ms": round(transcription_time, 2),
                            "transcription_time_s": round(transcription_time / 1000, 3),
                            "audio_duration_s": round(audio_duration, 3),
                            "realtime_factor": round(rtf, 2),
                            "samples": len(audio)
                        }
                    }))

            except json.JSONDecodeError:
                await websocket.send(json.dumps({
                    "type": "error",
                    "message": "Invalid JSON",
                }))
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                await websocket.send(json.dumps({
                    "type": "error",
                    "message": str(e),
                }))

    except websockets.exceptions.ConnectionClosed:
        print(f"üîå –ö–ª–∏–µ–Ω—Ç –æ—Ç–∫–ª—é—á–∏–ª—Å—è: {client_id}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ handle_client: {e}")
    finally:
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏
        if client_id in speakers_sessions:
            total_speakers = len(speakers_sessions[client_id])
            print(f"üëã –°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {client_id} | –í—Å–µ–≥–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {total_speakers}")
            del speakers_sessions[client_id]
            del speaker_counter[client_id]
        else:
            print(f"üëã –°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {client_id}")


async def main():
    """–ó–∞–ø—É—Å–∫ WebSocket —Å–µ—Ä–≤–µ—Ä–∞"""
    server = await websockets.serve(
        handle_client,
        "0.0.0.0",
        8765,
        ping_interval=20,
        ping_timeout=20,
        max_size=10 * 1024 * 1024  # 10MB max message size
    )
    
    print("üéß –û–∂–∏–¥–∞—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π...")
    await server.wait_closed()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nüëã –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
